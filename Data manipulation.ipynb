{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">__multi-class classification model for product category prediction: Data Manipulation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from warnings import simplefilter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">I decided to use the customers activities in the category he has purchased from __only in the same date as the order date__.\n",
    "<br>activities who didn't end up in a purchase will recieve category 0. this will empower the model by abling it to also predict if a costumer will not purchase at all.<br>\n",
    "activities that were made at the same day but after the order will be deleted from the data, as those rows represent activities can't influence the order since it already happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data:\n",
    "online = pd.read_csv(\"online.csv\")\n",
    "order = pd.read_csv(\"order.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joining the order data to the online data according based on the category,date and custno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating string column for date string only:\n",
    "remove_time_string= lambda x : x[:10]\n",
    "online[\"date_string\"]=online[\"dt\"].apply(remove_time_string)\n",
    "order[\"date_string\"]=order[\"orderdate\"].apply(remove_time_string)\n",
    "\n",
    "#turning custno prodcat1, and category to string :\n",
    "online['custno'] = online['custno'].apply(str)\n",
    "online['category'] = online['category'].apply(str)\n",
    "\n",
    "order['custno'] = order['custno'].apply(str)\n",
    "order['prodcat1'] = order['prodcat1'].apply(str)\n",
    "\n",
    "# concating category(prodcat1)+custno+date_string:\n",
    "online[\"cat+custno+date\"] = online[\"category\"] +'_'+ online[\"custno\"] +'_'+ online[\"date_string\"]\n",
    "order[\"cat+custno+date\"] = order[\"prodcat1\"] +'_'+ order[\"custno\"] +'_'+ order[\"date_string\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplilcate columns from order to enable joining with online:\n",
    "order_for_join=order.drop(columns=['custno', 'date_string'])\n",
    "\n",
    "#joining the two tables while keeping online lines that don't correspond (left join):\n",
    "joined_data=online.set_index('cat+custno+date').join(order_for_join.set_index('cat+custno+date'),how='left')\n",
    "joined_data.sort_values(by='revenue', ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing activities that occurred after the purchase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.fillna(0,inplace=True)\n",
    "\n",
    "# turning dt and orderdate columns to datetime objects:\n",
    "joined_data['dt']= pd.to_datetime(joined_data['dt'])\n",
    "joined_data['orderdate']= pd.to_datetime(joined_data['orderdate'])\n",
    "\n",
    "#checking which rows represent activities that happen after the purchase:\n",
    "joined_data['activity_after_order'] = np.where((joined_data['dt']>=joined_data['orderdate']) & (joined_data['ordno']!=0),True,False)\n",
    "\n",
    "#removing rows that represent activities that happen after the purchase:\n",
    "joined_data=joined_data[joined_data['activity_after_order']==False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">The next steps will involve transforming the data to having a unique row per each order and adding the variables I suspect to influence the target variable (the order category): <br>\n",
    "    \n",
    "- __event1 and event2 values:__ assuming those values are ids and both are created due to the same activity, the best practice is to combined them as one. the way I think will generate the most learning from them is to turn each combined value to a column as its value will be the number of times it occurred per \"order\"\n",
    "\n",
    "- __number of activities:__ total numbers of activities (event1 and 2 combination) each order generated.\n",
    "\n",
    "- __seconds diff between first and last activity:__ the time which passed between the first activity and the last one per \"order\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing prodcat2 and revenue columns (unnecessary for the model and create 'duplicate lines'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.drop(['revenue', 'prodcat2'], axis=1,inplace=True)\n",
    "joined_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a column that represent the events combinations (event1+event2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concating event2 & event1:\n",
    "joined_data['event1'] = joined_data['event1'].apply(int)\n",
    "joined_data['event2'] = joined_data['event2'].apply(int)\n",
    "\n",
    "joined_data['event1'] = joined_data['event1'].apply(str)\n",
    "joined_data['event2'] = joined_data['event2'].apply(str)\n",
    "\n",
    "joined_data['event1_event2_combined']=joined_data['event1'] +'_'+ joined_data['event2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a unique row per order table and adding extra variables ('seconds diff between first and last activity', 'num of activities'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping the data and aggregating wanted variables:\n",
    "joined_data_raw_per_order=joined_data.groupby(['cat+custno+date','custno','category','ordno','orderdate','prodcat1']).agg({'dt': ['min', 'max'],'event1_event2_combined':['count']})\n",
    "\n",
    "#changing the new columns names and removing the indexing:\n",
    "joined_data_raw_per_order.columns = ['dt_min', 'dt_max','activities_per_order']\n",
    "joined_data_raw_per_order.reset_index(inplace=True)\n",
    "\n",
    "# generating the seconds diff column:\n",
    "joined_data_raw_per_order['total_activities_time_seconds']=(joined_data_raw_per_order.dt_max-joined_data_raw_per_order.dt_min).dt.seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turning each combined value of the events to a column and counting their occurances per \"order\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to apply pivot func:\n",
    "joined_data_grouped_for_pivot=joined_data.groupby(['cat+custno+date','ordno','orderdate','prodcat1','event1_event2_combined'])['event1_event2_combined'].count()\n",
    "joined_data_grouped_for_pivot=joined_data_grouped_for_pivot.rename(columns={'event1_event2_combined':'event1_event2_combined_count'})\n",
    "joined_data_grouped_for_pivot=joined_data_grouped_for_pivot.to_frame()\n",
    "joined_data_grouped_for_pivot.reset_index(inplace=True)\n",
    "joined_data_grouped_for_pivot=joined_data_grouped_for_pivot.rename(columns={0:'event1_event2_combined_count'})\n",
    "\n",
    "joined_data_grouped_for_pivot['cat+custno+date,ordno,orderdate,prodcat1'] = joined_data_grouped_for_pivot['cat+custno+date'].astype(str) +'_'+ joined_data_grouped_for_pivot['ordno'].astype(str) +'_'+ joined_data_grouped_for_pivot['orderdate'].astype(str)+'_'+ joined_data_grouped_for_pivot['prodcat1'].astype(str)\n",
    "joined_data_grouped_for_pivot.set_index('cat+custno+date,ordno,orderdate,prodcat1',inplace=True)\n",
    "\n",
    "joined_data_grouped_for_pivot.reset_index(inplace=True)\n",
    "activities_count_df=pd.pivot_table(joined_data_grouped_for_pivot, values='event1_event2_combined_count', index='cat+custno+date,ordno,orderdate,prodcat1',columns=['event1_event2_combined'], aggfunc=np.sum)\n",
    "                                                       \n",
    "activities_count_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing \"joined_data_raw_per_order\" the data for merging with \"activities_count_df\" by creating a common column:\n",
    "joined_data_raw_per_order['cat+custno+date,ordno,orderdate,prodcat1'] = joined_data_raw_per_order['cat+custno+date'].astype(str) +'_'+ joined_data_raw_per_order['ordno'].astype(str) +'_'+ joined_data_raw_per_order['orderdate'].astype(str)+'_'+ joined_data_raw_per_order['prodcat1'].astype(str)\n",
    "\n",
    "#merging the tables:\n",
    "joined_data=joined_data_raw_per_order.merge(activities_count_df, left_on=['cat+custno+date,ordno,orderdate,prodcat1'], right_on=['cat+custno+date,ordno,orderdate,prodcat1'])\n",
    "joined_data.reset_index(inplace=True)\n",
    "\n",
    "# extracting a file for the model deployment ('Machine Learning.ipynb'):\n",
    "joined_data.to_csv('final_manipulated_data_ready_for_models.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Machine Learning part is in the Jupyter notebook file: \"'Machine Learning.ipynb'\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
